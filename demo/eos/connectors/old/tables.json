  {
  "connector.class": "io.streamthoughts.kafka.connect.filepulse.source.FilePulseSourceConnector",

    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false",

  "tasks.max": 1,

  "filters": "ParseDelimitedRow",
  "filters.ParseDelimitedRow.extractColumnName": "headers",
  "filters.ParseDelimitedRow.trimColumn": "true",
  "filters.ParseDelimitedRow.type": "io.streamthoughts.kafka.connect.filepulse.filter.DelimitedRowFilter",


  "tasks.reader.class": "io.streamthoughts.kafka.connect.filepulse.fs.reader.LocalRowFileInputReader",
  "topic": "xxx",
  "file.filter.regex.pattern": ".*\\.csv$",

  "offset.strategy": "name",

  "fs.listing.directory.path": "/etc/kafka-connect/jars/datagen/",
  "_fs.scan.interval.ms": "10000",
  "_fs.scan.filters": "io.streamthoughts.kafka.connect.filepulse.scanner.local.filter.RegexFileListFilter",

  "fs.listing.class": "io.streamthoughts.kafka.connect.filepulse.fs.LocalFSDirectoryListing",
  
  "fs.listing.filters":"io.streamthoughts.kafka.connect.filepulse.fs.filter.RegexFileListFilter",
  "fs.listing.interval.ms": "10000",

  "fs.cleanup.policy.class": "io.streamthoughts.kafka.connect.filepulse.fs.clean.LogCleanupPolicy",

  "tasks.file.status.storage.class": "io.streamthoughts.kafka.connect.filepulse.state.KafkaFileObjectStateBackingStore",
  "tasks.file.status.storage.topic": "connect-file-pulse-status",
  "tasks.file.status.storage.topic.partitions": 10,
  "tasks.file.status.storage.topic.replication.factor": 1,
  "tasks.file.status.storage.bootstrap.servers": "broker-1:9092",

  "skip.headers": "1"
}

